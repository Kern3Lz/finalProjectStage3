{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title"
      },
      "source": [
        "# ü§ñ Smart Cage - Model Training & Evaluation\n",
        "\n",
        "**Samsung Innovation Campus - Phase 3**\n",
        "\n",
        "Notebook ini untuk:\n",
        "- Load dataset CSV\n",
        "- Train model ML dengan scikit-learn\n",
        "- Evaluate model (Accuracy, Precision, Recall, Confusion Matrix)\n",
        "- Save trained model sebagai .pkl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1"
      },
      "source": [
        "## üì¶ Step 1: Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install"
      },
      "outputs": [],
      "source": [
        "!pip install pandas numpy scikit-learn matplotlib seaborn joblib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2"
      },
      "source": [
        "## üìö Step 2: Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "import"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import (accuracy_score, precision_score, \n",
        "                             recall_score, f1_score, \n",
        "                             confusion_matrix, classification_report)\n",
        "\n",
        "print(\"‚úÖ Libraries imported!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3"
      },
      "source": [
        "## üìÇ Step 3: Upload Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upload"
      },
      "outputs": [],
      "source": [
        "# Upload CSV file\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Assume file name\n",
        "import os\n",
        "csv_file = list(uploaded.keys())[0]\n",
        "print(f\"üìÅ Uploaded: {csv_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4"
      },
      "source": [
        "## ÔøΩÔøΩ Step 4: Load & Explore Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv(csv_file)\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"üìä DATASET INFO\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Total Rows: {len(df)}\")\n",
        "print(f\"Columns: {list(df.columns)}\")\n",
        "print(\"\\nüìã First 5 rows:\")\n",
        "display(df.head())\n",
        "\n",
        "print(\"\\nüìà Label Distribution:\")\n",
        "print(df[\"label\"].value_counts())\n",
        "\n",
        "print(\"\\nüìä Statistical Summary:\")\n",
        "display(df.describe())\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\n‚ùì Missing Values:\")\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5"
      },
      "source": [
        "## üé® Step 5: Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "viz"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "# Plot 1: Label distribution\n",
        "df[\"label\"].value_counts().plot(kind=\"bar\", ax=axes[0], color=[\"green\", \"red\", \"blue\"])\n",
        "axes[0].set_title(\"Label Distribution\")\n",
        "axes[0].set_xlabel(\"Label\")\n",
        "axes[0].set_ylabel(\"Count\")\n",
        "\n",
        "# Plot 2: Temperature vs Humidity scatter\n",
        "for label in df[\"label\"].unique():\n",
        "    subset = df[df[\"label\"] == label]\n",
        "    axes[1].scatter(subset[\"temperature\"], subset[\"humidity\"], label=label, alpha=0.6)\n",
        "axes[1].set_title(\"Temperature vs Humidity\")\n",
        "axes[1].set_xlabel(\"Temperature (¬∞C)\")\n",
        "axes[1].set_ylabel(\"Humidity (%)\")\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6"
      },
      "source": [
        "## ‚úÇÔ∏è Step 6: Split Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "split"
      },
      "outputs": [],
      "source": [
        "# Features & Target\n",
        "X = df[[\"temperature\", \"humidity\"]]\n",
        "y = df[\"label\"]\n",
        "\n",
        "# Split 80/20\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"‚úÇÔ∏è DATASET SPLIT\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Training set: {len(X_train)} samples\")\n",
        "print(f\"Test set: {len(X_test)} samples\")\n",
        "print(f\"\\nTrain labels distribution:\")\n",
        "print(y_train.value_counts())\n",
        "print(f\"\\nTest labels distribution:\")\n",
        "print(y_test.value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7"
      },
      "source": [
        "## ü§ñ Step 7: Train Model (Decision Tree)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train"
      },
      "outputs": [],
      "source": [
        "# Train Decision Tree\n",
        "model = DecisionTreeClassifier(random_state=42, max_depth=5)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"‚úÖ Model trained!\")\n",
        "print(f\"Model: {type(model).__name__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8"
      },
      "source": [
        "## üìä Step 8: Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eval"
      },
      "outputs": [],
      "source": [
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average=\"weighted\")\n",
        "recall = recall_score(y_test, y_pred, average=\"weighted\")\n",
        "f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"üìä MODEL EVALUATION METRICS\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"‚úÖ Accuracy  : {accuracy*100:.2f}%\")\n",
        "print(f\"‚úÖ Precision : {precision*100:.2f}%\")\n",
        "print(f\"‚úÖ Recall    : {recall*100:.2f}%\")\n",
        "print(f\"‚úÖ F1-Score  : {f1*100:.2f}%\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "print(\"\\nüìã Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9"
      },
      "source": [
        "## üìà Step 9: Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cm"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "labels = sorted(df[\"label\"].unique())\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
        "            xticklabels=labels, yticklabels=labels)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüìä Confusion Matrix:\")\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s10"
      },
      "source": [
        "## üíæ Step 10: Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "save"
      },
      "outputs": [],
      "source": [
        "model_filename = \"smart_cage_model.pkl\"\n",
        "joblib.dump(model, model_filename)\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"üíæ MODEL SAVED!\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"üìÅ Filename: {model_filename}\")\n",
        "print(f\"üìä Model Type: {type(model).__name__}\")\n",
        "print(f\"‚úÖ Accuracy: {accuracy*100:.2f}%\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Download model\n",
        "files.download(model_filename)\n",
        "print(\"\\nüì• Model downloaded! Upload this .pkl file to your dashboard.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s11"
      },
      "source": [
        "## üß™ Step 11: Test Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "test"
      },
      "outputs": [],
      "source": [
        "# Test dengan data baru\n",
        "test_data = [\n",
        "    [30.5, 65],  # Should be Ideal\n",
        "    [38, 55],    # Should be Panas\n",
        "    [25, 70]     # Should be Dingin\n",
        "]\n",
        "\n",
        "predictions = model.predict(test_data)\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"üß™ TEST PREDICTIONS\")\n",
        "print(\"=\" * 50)\n",
        "for i, (data, pred) in enumerate(zip(test_data, predictions)):\n",
        "    print(f\"Test {i+1}: T={data[0]}¬∞C, H={data[1]}% ‚Üí {pred}\")\n",
        "print(\"=\" * 50)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
